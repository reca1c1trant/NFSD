{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src.filepath import ABSOLUTE_PATH\n",
    "from src.model.diffusion import GaussianDiffusion\n",
    "from src.model.UNet2d import Unet2D\n",
    "from src.model.fno import FNO2D\n",
    "from src.utils.utils import plot_compare_2d, relative_error\n",
    "from src.train.reaction_diffusion import cond_emb, renormalize\n",
    "from src.train.reaction_diffusion import normalize_to_neg_one_to_one as normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"Unet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 24\n",
    "out_dim = 1\n",
    "channel = 3\n",
    "nx = 20\n",
    "diffusion_step = 250\n",
    "device = \"cuda\"\n",
    "if model_type == \"Unet\":\n",
    "    model1 = Unet2D(dim=dim, cond_emb=cond_emb(), out_dim=out_dim, dim_mults=(1, 2), channels=channel)\n",
    "    model2 = Unet2D(dim=dim, cond_emb=cond_emb(), out_dim=out_dim, dim_mults=(1, 2), channels=channel)\n",
    "elif model_type == \"ViT\":\n",
    "    model1 = ViT(\n",
    "        seq_len=20,\n",
    "        patch_size=2,\n",
    "        dim=64,\n",
    "        depth=2,\n",
    "        heads=8,\n",
    "        mlp_dim=128,\n",
    "        cond_emb=cond_emb(),\n",
    "        Time_Input=True,\n",
    "        dropout=0.0,\n",
    "        emb_dropout=0.0,\n",
    "        channels=20,\n",
    "        out_channels=9,\n",
    "    ).to(\"cuda\")\n",
    "    model2 = ViT(\n",
    "        seq_len=20,\n",
    "        patch_size=2,\n",
    "        dim=64,\n",
    "        depth=2,\n",
    "        heads=8,\n",
    "        mlp_dim=128,\n",
    "        cond_emb=cond_emb(),\n",
    "        Time_Input=True,\n",
    "        dropout=0.0,\n",
    "        emb_dropout=0.0,\n",
    "        channels=20,\n",
    "        out_channels=9,\n",
    "    ).to(\"cuda\")\n",
    "elif model_type == \"FNO\":\n",
    "    model1 = FNO2D(\n",
    "        in_channels=channel,\n",
    "        out_channels=out_dim,\n",
    "        nr_fno_layers=4,\n",
    "        fno_layer_size=24,\n",
    "        fno_modes=[6, 12],\n",
    "        time_input=True,\n",
    "        cond_emb=cond_emb(),\n",
    "    )\n",
    "    model2 = FNO2D(\n",
    "        in_channels=channel,\n",
    "        out_channels=out_dim,\n",
    "        nr_fno_layers=4,\n",
    "        fno_layer_size=24,\n",
    "        fno_modes=[6, 12],\n",
    "        time_input=True,\n",
    "        cond_emb=cond_emb(),\n",
    "    )\n",
    "diffusion1 = GaussianDiffusion(model1, seq_length=(out_dim, 10, nx), timesteps=diffusion_step, auto_normalize=False).to(\n",
    "    device\n",
    ")\n",
    "diffusion2 = GaussianDiffusion(model2, seq_length=(out_dim, 10, nx), timesteps=diffusion_step, auto_normalize=False).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"Unet\":\n",
    "    diffusion1.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionUnetu10000/model.pt\")[\"model\"])\n",
    "    diffusion2.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionUnetv10000/model.pt\")[\"model\"])\n",
    "elif model_type == \"ViT\":\n",
    "    diffusion1.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionViTu10000/model.pt\")[\"model\"])\n",
    "    diffusion2.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionViTv10000/model.pt\")[\"model\"])\n",
    "elif model_type == \"FNO\":\n",
    "    diffusion1.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionFNOu10000/model.pt\")[\"model\"])\n",
    "    diffusion2.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionFNOv10000/model.pt\")[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    torch.tensor(np.load(ABSOLUTE_PATH + \"/data/reaction_diffusion/reaction_diffusion_uv.npy\"))\n",
    "    .float()\n",
    "    .to(\"cuda\")[:2000]\n",
    ")\n",
    "# data = (data + 5) / 10\n",
    "\n",
    "data = data.permute(0, 2, 1)\n",
    "\n",
    "# data1 = np.load('../../data/reaction_diffusion_u_from_v_u.npy')\n",
    "\n",
    "u, v = data[..., :20].unsqueeze(1), data[..., 20:].unsqueeze(1)\n",
    "\n",
    "u_intial, v_intial = u[:, :, 0:1].expand(-1, -1, 10, -1), v[:, :, 0:1].expand(-1, -1, 10, -1)\n",
    "\n",
    "u.shape, u_intial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_u(\n",
    "    alpha, t, model, field_noise, mult_p_estimate, mult_p_estimate_before, other_condition, normalize, renormalize\n",
    "):\n",
    "    weight_field = []\n",
    "    for i in range(len(mult_p_estimate)):\n",
    "        weight_field.append(alpha * mult_p_estimate[i] + (1 - alpha) * mult_p_estimate_before[i])\n",
    "    intial_u, intial_v = other_condition[0], other_condition[1]\n",
    "    cond = [torch.concat((weight_field[1], intial_u), dim=1)]\n",
    "    field_noise_next, x0 = model.p_sample(field_noise, t, cond)\n",
    "    return field_noise_next, x0\n",
    "\n",
    "\n",
    "def update_v(\n",
    "    alpha, t, model, field_noise, mult_p_estimate, mult_p_estimate_before, other_condition, normalize, renormalize\n",
    "):\n",
    "    weight_field = []\n",
    "    for i in range(len(mult_p_estimate)):\n",
    "        weight_field.append(alpha * mult_p_estimate[i] + (1 - alpha) * mult_p_estimate_before[i])\n",
    "    intial_u, intial_v = other_condition[0], other_condition[1]\n",
    "    cond = [torch.concat((weight_field[0], intial_v), dim=1)]\n",
    "    field_noise_next, x0 = model.p_sample(field_noise, t, cond)\n",
    "    return field_noise_next, x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_diffusion(\n",
    "    model_list,\n",
    "    shape: list,\n",
    "    update_f: list,\n",
    "    normalize_f,\n",
    "    unnormalize_f,\n",
    "    other_condition=[],\n",
    "    num_iter=2,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"compose diffusion model\n",
    "\n",
    "    Args:\n",
    "        model_list (_type_):conditional diffusion model for each physics field\n",
    "        shape (_type_): shape of field: b, c, *\n",
    "        update_f (list): update function for each physics field\n",
    "        normalize_f (_type_, optional): normalization function for each physics field.\n",
    "        unnormalize_f (_type_, optional): unnormalization function for each physics field.\n",
    "        other_condition (list): other_condition such as initial state, source term.\n",
    "        num_iter: (int, optional): outer iteration. Defaults to 2.\n",
    "        device (str, optional): _description_. Defaults to 'cuda'.\n",
    "    Returns:\n",
    "        list: a list contains each field\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "\n",
    "        n_compose = len(model_list)\n",
    "\n",
    "        timestep = model_list[0].num_timesteps\n",
    "\n",
    "        # initial field\n",
    "        mult_p_estimate = []\n",
    "        for s in shape:\n",
    "            mult_p_estimate.append(torch.randn(s, device=device))\n",
    "\n",
    "        for k in range(num_iter):\n",
    "            mult_p_estimate_before = mult_p_estimate.copy()\n",
    "            mult_p_estimate = []\n",
    "            mult_p = []\n",
    "            for s in shape:\n",
    "                mult_p_estimate.append(torch.randn(s, device=device))\n",
    "                mult_p.append(torch.randn(s, device=device))\n",
    "            for t in tqdm(reversed(range(0, timestep)), desc=\"sampling loop time step\", total=timestep):\n",
    "                alpha = 0 if k > 0 else 1\n",
    "                # linear: 1 - t / (timestep - 1), 0->1\n",
    "                # cos: cos(math.pi/2(t / (timestep - 1))), 0->1\n",
    "                # power1: 1 - (t / (timestep - 1))**2\n",
    "                # power2: (t / (timestep - 1)-1)**2\n",
    "                for i in range(n_compose):\n",
    "                    # condition\n",
    "                    model = model_list[i]\n",
    "                    update = update_f[i]\n",
    "                    single_p, x0 = update(\n",
    "                        alpha,\n",
    "                        t,\n",
    "                        model,\n",
    "                        mult_p[i].clone(),\n",
    "                        mult_p_estimate.copy(),\n",
    "                        mult_p_estimate_before.copy(),\n",
    "                        other_condition,\n",
    "                        normalize_f,\n",
    "                        unnormalize_f,\n",
    "                    )\n",
    "                    mult_p[i] = single_p\n",
    "\n",
    "                    # update estimated physics field\n",
    "\n",
    "                    mult_p_estimate[i] = model.unnormalize(x0)\n",
    "    return mult_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lis = [diffusion1, diffusion2]\n",
    "mult_p = compose_diffusion(\n",
    "    model_list=model_lis,\n",
    "    shape=[(u.shape[0], 1, 10, 20), (u.shape[0], 1, 10, 20)],\n",
    "    other_condition=[normalize(u_intial), normalize(v_intial)],\n",
    "    update_f=[update_u, update_v],\n",
    "    normalize_f=[normalize, normalize],\n",
    "    unnormalize_f=[renormalize, renormalize],\n",
    "    num_iter=2,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_p_true = torch.concat((u, v), dim=1)\n",
    "mult_p_pred = renormalize(torch.concat((mult_p[0], mult_p[1]), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relative_error(mult_p_pred[:, 0], mult_p_true[:, 0]), relative_error(mult_p_pred[:, 1], mult_p_true[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
