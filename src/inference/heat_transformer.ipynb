{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\mpd\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\vscode/research/multphysics_simulation\\src\\model\\diffusion.py:478: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GIN\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys, os\n",
    "\n",
    "from torch_geometric.data import Data as Data_g\n",
    "from torch_geometric.data import DataLoader as DataLoader_G\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# import path\n",
    "sys.path.append(\"../\")\n",
    "from filepath import ABSOLUTE_PATH\n",
    "\n",
    "sys.path.append(ABSOLUTE_PATH)\n",
    "from src.train.heatpipe_transformer import load_data, SAN\n",
    "from src.train.heatpipe import renormalize\n",
    "from src.train.train import Trainer\n",
    "from src.utils.utils import (\n",
    "    create_res,\n",
    "    set_seed,\n",
    "    get_time,\n",
    "    save_config_from_args,\n",
    "    get_parameter_net,\n",
    "    find_max_min,\n",
    "    relative_error,\n",
    ")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "num_layers_NF, hidden_dim = 4, 512\n",
    "loss = np.load(\n",
    "    \"../../results/heatpipe/surrogate/transformer\"\n",
    "    + \"_\"\n",
    "    + str(hidden_dim)\n",
    "    + \"_1024_\"\n",
    "    + str(num_layers_NF)\n",
    "    + \"/record.py\"\n",
    ")\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAN(\n",
    "    input_dim=4,\n",
    "    output_dim=2412,\n",
    "    hidden_dim=hidden_dim,\n",
    "    k=32,\n",
    "    m=8,\n",
    "    num_heads_PE=4,\n",
    "    dim_feedforward_PE=64,\n",
    "    dropout_PE=0.1,\n",
    "    num_layers_PE=1,\n",
    "    num_heads_NF=8,\n",
    "    dim_feedforward_NF=1024,\n",
    "    dropout_NF=0.1,\n",
    "    num_layers_NF=num_layers_NF,\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"../../results/heatpipe/surrogate/transformer\"\n",
    "        + \"_\"\n",
    "        + str(hidden_dim)\n",
    "        + \"_1024_\"\n",
    "        + str(num_layers_NF)\n",
    "        + \"/model.pt\"\n",
    "    )[\"model\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_loader = load_data(ABSOLUTE_PATH, 200, 800, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    x, pe, y = batch\n",
    "    y_p = renormalize(model(x, pe))\n",
    "y_t = renormalize(y)  # .reshape(-1, 804, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error(y_t[..., 0], y_p[..., 0]), relative_error(y_t[..., 1:], y_p[..., 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import get_laplacian, degree, add_self_loops\n",
    "\n",
    "m = 8\n",
    "x_val = (\n",
    "    torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/x_val_element_as_one_node.npy\"))\n",
    "    .to(device)\n",
    "    .float()\n",
    "    .unsqueeze(0)\n",
    ")\n",
    "y_val_t = (\n",
    "    torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/y_val_element_as_one_node.npy\"))\n",
    "    .to(device)\n",
    "    .float()\n",
    "    .unsqueeze(0)\n",
    ")\n",
    "\n",
    "# ? Now all data share one graph\n",
    "edge_index = torch.tensor(\n",
    "    np.load(ABSOLUTE_PATH + \"/data/heatpipe/adj_val_element_as_one_node.npy\").transpose(1, 0), dtype=torch.long\n",
    ").to(device)\n",
    "edge_index, edge_weight = get_laplacian(edge_index)\n",
    "adjacency_matrix = torch.sparse_coo_tensor(edge_index, edge_weight)\n",
    "deg = torch.bincount(edge_index[0], minlength=64)\n",
    "deg_matrix = torch.diag(deg)\n",
    "laplacian_matrix = deg_matrix - adjacency_matrix\n",
    "\n",
    "eigvals, eigvecs = torch.linalg.eigh(laplacian_matrix)  # low to high\n",
    "top_eigvals = eigvals[-m:]  # top m\n",
    "top_eigvecs = eigvecs[:, -m:]\n",
    "eigvals_ep = top_eigvals.unsqueeze(0).repeat(top_eigvecs.shape[0], 1)\n",
    "PE = torch.cat((eigvals_ep.unsqueeze(1), top_eigvecs.unsqueeze(1)), dim=1)\n",
    "PE_val = PE.unsqueeze(0).repeat(x_val.shape[0], 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_p = renormalize(model(x_val, PE_val))\n",
    "relative_error(y_val_t[..., 0], y_val_p[..., 0]), relative_error(y_val_t[..., 1:], y_val_p[..., 1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
